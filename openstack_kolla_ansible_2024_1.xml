<?xml version="1.0" encoding="UTF-8"?>

<!--
~~~~~~~~~~~~~~~~~~~~~~
 VNX Sample scenarios
~~~~~~~~~~~~~~~~~~~~~~

Name:        openstack_kolla_ansible

Description: This is an Openstack tutorial scenario designed to experiment with Openstack free and open-source
             software platform for cloud-computing. It is made of four kvm machines:
               - one controller
               - one network node
               - two compute nodes
             Kolla-ansible is used to provision OpenStack platform.
             Openstack version used: Wallaby.
             The network configuration is based on the one named "Classic with Open vSwitch" described here:
                  http://docs.openstack.org/liberty/networking-guide/scenario-classic-ovs.html

Author:      Nacho Dominguez (i.dominguezm@upm.es)

This file is part of the Virtual Networks over LinuX (VNX) Project distribution.
(www: http://www.dit.upm.es/vnx - e-mail: vnx@dit.upm.es)

Copyright (C) 2021 Networking and Virtualization Research Group (GIROS)
        Departamento de Ingenieria de Sistemas Telematicos (DIT)
	      Universidad Politecnica de Madrid (UPM)
        SPAIN
-->

<vnx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:noNamespaceSchemaLocation="/usr/share/xml/vnx/vnx-2.00.xsd">
  <global>
    <version>2.0</version>
    <scenario_name>openstack_kolla_openstack</scenario_name>
    <ssh_key>conf/ssh/id_rsa.pub</ssh_key>
    <automac/>
    <vm_mgmt type="private" network="192.168.50.0" mask="24" offset="16">
       <host_mapping />
    </vm_mgmt>
    <vm_defaults>
        <console id="0" display="no"/>
        <console id="1" display="yes"/>
    </vm_defaults>
    <cmd-seq seq="config-admin">config-admin1,config-admin2,setup-nfs</cmd-seq>
  </global>

  <net name="MgmtNet" mode="openvswitch" mtu="1450"/>
  <net name="TunnNet" mode="openvswitch" mtu="1450"/>
  <net name="ExtNet"  mode="openvswitch" />
  <net name="VlanNet" mode="openvswitch" />
  <net name="virbr0"  mode="virtual_bridge" managed="no"/>

  <!--
    ~~
    ~~   A D M I N   N O D E
    ~~
  -->
  <vm name="admin" type="lxc" exec_mode="lxc-attach" arch="x86_64">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_lxc_ubuntu64-22.04-v025</filesystem>
    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.1/24</ipv4>
    </if>
    <if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if>
    <filetree seq="on_boot" root="/usr/bin/">/usr/bin/vnx_config_nat</filetree>
    <filetree seq="on_boot" root="/root/.ssh/">conf/ssh/id_rsa</filetree>
    <filetree seq="on_boot" root="/tmp/">conf/admin/hosts</filetree>
    <filetree seq="on_boot" root="/root/">conf/admin/deploy-ostack</filetree>

    <!-- Añadido por Pablo. Archivos necesarios para configurar Ceilometer -->
    <filetree seq="on_boot" root="/tmp/">conf/admin/pipeline.yaml</filetree>
    <filetree seq="on_boot" root="/tmp/">conf/admin/polling.yaml</filetree>
    <filetree seq="on_boot" root="/tmp/">conf/admin/event_definitions.yaml.j2</filetree>

    <!-- Añadido por Pablo. Archivos necesarios para configurar Swift -->
    <filetree seq="on_boot" root="/root/">conf/admin/rings-swift</filetree>

    <exec seq="on_boot" type="verbatim">
        dhclient eth9
        apt-get update
        apt-get install -y iptables
        /usr/bin/vnx_config_nat eth1 eth9
	sudo chown 644 /root/.ssh/id_rsa
	cat /tmp/hosts >> /etc/hosts
	rm /tmp/hosts
	for c in controller network compute1 compute2 compute3; do
            while ! $( nc -z $c 22 ); do sleep 1; done
	    ssh -o StrictHostKeyChecking=accept-new root@$c w
        done
	#ssh -o StrictHostKeyChecking=accept-new root@network w
	#ssh -o StrictHostKeyChecontrollercking=accept-new root@compute1 w
	#ssh -o StrictHostKeyChecking=accept-new root@compute2 w
    </exec>
    <exec seq="config-admin1" type="verbatim">
	for c in controller network compute1 compute2 compute3; do while ! $( nc -z $c 22 ); do sleep 1; done; ssh -o StrictHostKeyChecking=accept-new root@$c w; done
        for c in 10.0.0.11 10.0.0.21 10.0.0.31 10.0.0.32 10.0.0.33; do while ! $( nc -z $c 22 ); do sleep 1; done; ssh -o StrictHostKeyChecking=accept-new root@$c w; done
	for c in controller network compute1 compute2 compute3; do apt updetcate; done
        export DEBIAN_FRONTEND=noninteractive
        sudo apt update
        sudo apt install -y git python3-dev libffi-dev gcc libssl-dev python3-venv
	python3 -m venv /root/kolla
        source /root/kolla/bin/activate
        pip install -U pip
        <!-- Modificado por Pablo. Versiones de Ansible correspondientes a OpenStack v2024.1 -->
        pip install ansible 'ansible>=8,&lt;10' 
        pip install git+https://opendev.org/openstack/kolla-ansible@stable/2024.1
        sudo mkdir -p /etc/kolla
        sudo chown $USER:$USER /etc/kolla
        cp -r /root/kolla/share/kolla-ansible/etc_examples/kolla/* /etc/kolla
        cp /root/kolla/share/kolla-ansible/ansible/inventory/all-in-one .
        kolla-ansible install-deps
        kolla-genpwd
        sed -i 's/#kolla_base_distro:.*/kolla_base_distro: "ubuntu"/' /etc/kolla/globals.yml
        sed -i 's/#network_interface:.*/network_interface: "eth1"/' /etc/kolla/globals.yml
        sed -i 's/#neutron_external_interface:.*/neutron_external_interface: "eth3,eth4"/' /etc/kolla/globals.yml
        sed -i '/neutron_external_interface:/a neutron_bridge_name: "br-vlan,br-ex"' /etc/kolla/globals.yml
        sed -i 's/#kolla_internal_vip_address:.*/kolla_internal_vip_address: "10.0.0.250"/' /etc/kolla/globals.yml
        sed -i 's/#enable_neutron_provider_networks:.*/enable_neutron_provider_networks: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_ceilometer:.*/enable_ceilometer: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_gnocchi:.*/enable_gnocchi: "yes"/' /etc/kolla/globals.yml
        pip install python-openstackclient -c https://releases.openstack.org/constraints/upper/2024.1

        <!-- Añadido Por Pablo. Habilitar FWaaS-->
        sed -i 's/#enable_neutron_fwaas:.*/enable_neutron_fwaas: "yes"/' /etc/kolla/globals.yml

        <!-- Añadido Por Pablo. Habilitar Octavia-->
        pip install python-octaviaclient
        sed -i 's/#octavia_network_interface:.*/octavia_network_interface: "eth3.1005"/' /etc/kolla/globals.yml
        sed -i 's/#enable_octavia:.*/enable_octavia: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_redis:.*/enable_redis: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_horizon_octavia:.*/enable_horizon_octavia: "{{ enable_octavia | bool }}"/' /etc/kolla/globals.yml
        sed -i 's/#octavia_auto_configure:.*/octavia_auto_configure: "yes"/' /etc/kolla/globals.yml
        sed -i '/#octavia_amp_network:/,/enable_dhcp: yes/{
  /#octavia_amp_network:/{
    s/#octavia_amp_network:/octavia_amp_network:/g
  }
  /#    enable_dhcp: yes/{
    s/#    enable_dhcp: yes/octavia_amp_network:\n            name: lb-mgmt-net\n            provider_network_type: vlan\n            provider_segmentation_id: 1005\n            provider_physical_network: physnet1\n            external: false\n            shared: false\n            subnet:\n              name: lb-mgmt-subnet\n              cidr: "10.10.0.0\/24"\n              allocation_pool_start: "10.10.0.100"\n              allocation_pool_end: "10.10.0.200"\n              gateway_ip: "10.10.0.1"\n              enable_dhcp: yes\n/g
  }
}' /etc/kolla/globals.yml
        sed -i '0,/octavia_amp_network:/{s/octavia_amp_network:.*/#octavia_amp_network:/}' /etc/kolla/globals.yml

        <!-- Añadido Por Pablo. Mejorar rendimiento de Octavia. Valores por defecto: amp_active_retries = 100 y amp_active_wait_sec = 2-->
        sed -i -e 's/amp_active_retries =.*/amp_active_retries = 1000/' /root/kolla/share/kolla-ansible/ansible/roles/octavia/templates/octavia.conf.j2
        sed -i -e 's/amp_active_wait_sec =.*/amp_active_wait_sec = 2/' /root/kolla/share/kolla-ansible/ansible/roles/octavia/templates/octavia.conf.j2

        <!-- Añadido por David. Cambiar MTU a 1400 y así poder acceder por SSH-->
        sed -i -e 's/network_vlan_ranges =.*/network_vlan_ranges = physnet1/' /root/kolla/share/kolla-ansible/ansible/roles/neutron/templates/ml2_conf.ini.j2
        echo 'dhcp-option-force=26,1400' >> /root/kolla/share/kolla-ansible/ansible/roles/neutron/templates/dnsmasq.conf.j2

        <!-- Añadido por Pablo. Configuración de Aodh, Gnocchi y Ceilometer -->
        sed -i 's/#enable_aodh:.*/enable_aodh: "yes"/' /etc/kolla/globals.yml
        pip install aodhclient
        pip install gnocchiclient
        rm -rf /root/kolla/share/kolla-ansible/ansible/roles/ceilometer/templates/event_definitions.yaml.j2
        mv /tmp/event_definitions.yaml.j2 /root/kolla/share/kolla-ansible/ansible/roles/ceilometer/templates/event_definitions.yaml.j2

        mkdir -p /etc/kolla/config/ceilometer
        mv /tmp/pipeline.yaml /etc/kolla/config/ceilometer/pipeline.yaml
        mv /tmp/polling.yaml /etc/kolla/config/ceilometer/polling.yaml

        <!-- Añadido por Pablo. Habilitar Cinder-->
        sed -i 's/#enable_cinder:.*/enable_cinder: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_cinder_backup:.*/enable_cinder_backup: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#enable_cinder_backend_nfs:.*/enable_cinder_backend_nfs: "yes"/' /etc/kolla/globals.yml

        sed -i 's/#cinder_backup_driver:.*/cinder_backup_driver: "nfs"/' /etc/kolla/globals.yml
        sed -i 's/^#*\(cinder_backup_share:\).*/\1 "controller:\/kolla_nfs"/' /etc/kolla/globals.yml
        sed -i 's/#cinder_backup_mount_options_nfs:.*/cinder_backup_mount_options_nfs: ""/' /etc/kolla/globals.yml

        echo "controller:/kolla_nfs" >> /etc/kolla/config/nfs_shares
        chmod 777 /etc/kolla/config/nfs_shares

        <!-- Añadido por Pablo. Habilitar Skyline-->
        sed -i 's/#enable_skyline:.*/enable_skyline: "yes"/' /etc/kolla/globals.yml

        <!-- Añadido Por Pablo. Habilitar Swift-->
        pip install python-swiftclient
        sed -i 's/#enable_swift:.*/enable_swift: "yes"/' /etc/kolla/globals.yml
        sed -i 's/#swift_devices_match_mode:.*/swift_devices_match_mode: "prefix"/' /etc/kolla/globals.yml
        sed -i 's/#swift_devices_name:.*/swift_devices_name: "swd"/' /etc/kolla/globals.yml
        sed -i 's/#glance_backend_swift:.*/glance_backend_swift: "no"/' /etc/kolla/globals.yml
        
        sed -i '$ a\[storage-policy:0]\nname = Policy-0\ndefault = true' /root/kolla/share/kolla-ansible/ansible/roles/swift/templates/swift.conf.j2
        sed -i '/#swift_enable_rolling_upgrade: "yes"/a swift_delay_auth_decision: "yes"' /etc/kolla/globals.yml

        <!-- Añadido por Pablo. Otras utilidades-->
        apt-get install nano
        
    </exec>
    <filetree seq="config-admin2" root="/root/kolla/share/kolla-ansible/ansible/inventory/">conf/admin/multinode</filetree>
    <exec seq="config-admin2" type="verbatim">
        rm /root/kolla/share/kolla-ansible/ansible/inventory/all-in-one
    </exec>
    <exec seq="config-admin3" type="verbatim">
	# No funciona. Ejecutar manualmente
        source /root/kolla/bin/activate
        kolla-ansible -i /root/kolla/share/kolla-ansible/ansible/inventory/multinode --configdir /etc/kolla/ bootstrap-servers
        kolla-ansible -i /root/kolla/share/kolla-ansible/ansible/inventory/multinode --configdir /etc/kolla/ prechecks
        kolla-ansible -i /root/kolla/share/kolla-ansible/ansible/inventory/multinode --configdir /etc/kolla/ deploy
        kolla-ansible post-deploy

    </exec>

    <!-- Añadido por Pablo. Documentacion disponible en: https://docs.openstack.org/kolla-ansible/latest/reference/networking/octavia.html#octavia-amphora-image -->
    <exec seq="load-octavia" type="verbatim">

        source /root/kolla/bin/activate
        . /etc/kolla/octavia-openrc.sh

        wget -P /tmp/images http://vnx.dit.upm.es/vnx/filesystems/ostack-images/amphora-x64-haproxy.qcow2
        openstack image create amphora-x64-haproxy.qcow2 --container-format bare --disk-format qcow2 --private --tag amphora --file /tmp/images/amphora-x64-haproxy.qcow2 --property hw_architecture='x86_64' --property hw_rng_model=virtio
        rm /tmp/images/amphora-x64-haproxy.qcow2
        
    </exec>

    <exec seq="load-img" type="verbatim">

        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh

        # Create flavors if not created
        openstack flavor show m1.nano >/dev/null 2>&amp;1    || openstack flavor create --vcpus 1 --ram 64 --disk 1 m1.nano
        openstack flavor show m1.tiny >/dev/null 2>&amp;1    || openstack flavor create --vcpus 1 --ram 512 --disk 1 m1.tiny
        openstack flavor show m1.smaller >/dev/null 2>&amp;1 || openstack flavor create --vcpus 1 --ram 512 --disk 3 m1.smaller

        # Cirros image
        wget -P /tmp/images http://vnx.dit.upm.es/vnx/filesystems/ostack-images/cirros-0.3.4-x86_64-disk-vnx.qcow2
        openstack image create "cirros-0.3.4-x86_64-vnx" --file /tmp/images/cirros-0.3.4-x86_64-disk-vnx.qcow2 --disk-format qcow2 --container-format bare --public --progress
        rm /tmp/images/cirros-0.3.4-x86_64-disk*.qcow2

        # Ubuntu image (focal,20.04)
        rm -f /tmp/images/focal-server-cloudimg-amd64-vnx.qcow2
        wget -P /tmp/images http://vnx.dit.upm.es/vnx/filesystems/ostack-images/focal-server-cloudimg-amd64-vnx.qcow2
        openstack image create "focal-server-cloudimg-amd64-vnx" --file /tmp/images/focal-server-cloudimg-amd64-vnx.qcow2 --disk-format qcow2 --container-format bare --public --progress
        rm /tmp/images/focal-server-cloudimg-amd64-vnx.qcow2

        # Ubuntu image (jammy,22.04)
        rm -f /tmp/images/jammy-server-cloudimg-amd64-vnx.qcow2
        wget -P /tmp/images http://vnx.dit.upm.es/vnx/filesystems/ostack-images/jammy-server-cloudimg-amd64-vnx.qcow2
	      openstack image create "jammy-server-cloudimg-amd64-vnx" --file /tmp/images/jammy-server-cloudimg-amd64-vnx.qcow2 --disk-format qcow2 --container-format bare --public --progress
        rm /tmp/images/jammy-server-cloudimg-amd64-vnx.qcow2 
        
    </exec>

    <exec seq="create-extnet" type="verbatim">
        # Create external network
        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh
        openstack network create --share --external --provider-physical-network physnet2 --provider-network-type flat ExtNet
        openstack subnet create --network ExtNet --gateway 10.0.10.1 --dns-nameserver 10.0.10.1 --subnet-range 10.0.10.0/24 --allocation-pool start=10.0.10.100,end=10.0.10.200 ExtSubNet
    </exec>

    <!--
         CREATE DEMO SCENARIO
    -->
    <exec seq="create-demo-scenario" type="verbatim">
        source /root/kolla/bin/activate
	. /etc/kolla/admin-openrc.sh

        # Create internal network
        openstack network create net0
        openstack subnet create --network net0 --gateway 10.1.1.1 --dns-nameserver 8.8.8.8 --subnet-range 10.1.1.0/24 --allocation-pool start=10.1.1.8,end=10.1.1.100 subnet0

        # Create virtual machine
        mkdir -p /root/keys
        openstack keypair create vm1 > /root/keys/vm1
        openstack server create --flavor m1.tiny --image cirros-0.3.4-x86_64-vnx vm1 --nic net-id=net0 --key-name vm1

        # Create external network
        #openstack network create --share --external --provider-physical-network provider --provider-network-type flat ExtNet
        #openstack subnet create --network ExtNet --gateway 10.0.10.1 --dns-nameserver 10.0.10.1 --subnet-range 10.0.10.0/24 --allocation-pool start=10.0.10.100,end=10.0.10.200 ExtSubNet
        openstack router create r0
        openstack router set r0 --external-gateway ExtNet
        openstack router add subnet r0 subnet0

        # Assign floating IP address to vm1
        openstack server add floating ip vm1 $( openstack floating ip create ExtNet -c floating_ip_address -f value )

        # Create security group rules to allow ICMP, SSH and WWW access
        openstack security group rule create --proto icmp --dst-port 0  default
        openstack security group rule create --proto tcp  --dst-port 80 default
        openstack security group rule create --proto tcp  --dst-port 22 default

    </exec>

    <exec seq="create-demo-vm2" type="verbatim">
        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh
        # Create virtual machine
        mkdir -p /root/keys
        openstack keypair create vm2 > /root/keys/vm2
        openstack server create --flavor m1.tiny --image cirros-0.3.4-x86_64-vnx vm2 --nic net-id=Net1 --key-name vm2
        # Assign floating IP address to vm2
        #openstack ip floating add $( openstack ip floating create ExtNet -c ip -f value ) vm2
        openstack server add floating ip vm2 $( openstack floating ip create ExtNet -c floating_ip_address -f value )
    </exec>
        <exec seq="create-demo-vm3" type="verbatim">
        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh
        # Create virtual machine
        mkdir -p /root/keys
        openstack keypair create vm3 > /root/keys/vm3
        openstack server create --flavor m1.smaller --image focal-server-cloudimg-amd64-vnx vm3 --nic net-id=net0 --key-name vm3
        # Assign floating IP address to vm3
        #openstack ip floating add $( openstack ip floating create ExtNet -c ip -f value ) vm3
        openstack server add floating ip vm3 $( openstack floating ip create ExtNet -c floating_ip_address -f value )
    </exec>

    <exec seq="create-demo-vm4" type="verbatim">
        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh
        # Create virtual machine
        mkdir -p /root/keys
        openstack keypair create vm4 > /root/keys/vm4
        openstack server create --flavor m1.smaller --image jammy-server-cloudimg-amd64-vnx vm4 --nic net-id=net0 --key-name vm4 --property VAR1=2 --property VAR2=3
        # Assign floating IP address to vm4
        #openstack ip floating add $( openstack ip floating create ExtNet -c ip -f value ) vm4
        openstack server add floating ip vm4 $( openstack floating ip create ExtNet -c floating_ip_address -f value )
    </exec>

    <exec seq="create-vlan-demo-scenario" type="verbatim">
        source /root/kolla/bin/activate
        source /etc/kolla/admin-openrc.sh
        # Create security group rules to allow ICMP, SSH and WWW access
        admin_project_id=$(openstack project show admin -c id -f value)
        default_secgroup_id=$(openstack security group list -f value | grep $admin_project_id | cut -d " " -f1)
        openstack security group rule create --proto icmp --dst-port 0  $default_secgroup_id
        openstack security group rule create --proto tcp  --dst-port 80 $default_secgroup_id
        openstack security group rule create --proto tcp  --dst-port 22 $default_secgroup_id

        # Create vlan based networks and subnetworks
        openstack network create --share --provider-physical-network physnet1 --provider-network-type vlan --provider-segment 1000 vlan1000
        openstack network create --share --provider-physical-network physnet1 --provider-network-type vlan --provider-segment 1001 vlan1001
        openstack subnet create --network vlan1000 --gateway 10.1.2.1 --dns-nameserver 8.8.8.8 --subnet-range 10.1.2.0/24 --allocation-pool start=10.1.2.2,end=10.1.2.99 subvlan1000
        openstack subnet create --network vlan1001 --gateway 10.1.3.1 --dns-nameserver 8.8.8.8 --subnet-range 10.1.3.0/24 --allocation-pool start=10.1.3.2,end=10.1.3.99 subvlan1001

        # Create virtual machine
        mkdir -p tmp
        openstack keypair create vmA1 > tmp/vmA1
        openstack server create --flavor m1.tiny --image cirros-0.3.4-x86_64-vnx vmA1 --nic net-id=vlan1000 --key-name vmA1
        openstack keypair create vmB1 > tmp/vmB1
        openstack server create --flavor m1.tiny --image cirros-0.3.4-x86_64-vnx vmB1 --nic net-id=vlan1001 --key-name vmB1

    </exec>

  </vm>


  <!--
    ~~
    ~~   C O N T R O L L E R   N O D E
    ~~
  -->
  <vm name="controller" type="libvirt" subtype="kvm" os="linux" exec_mode="sdisk" arch="x86_64" vcpu="2">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_kvm_ubuntu64-22.04-v025.qcow2</filesystem>
    <mem>8G</mem> 
    <!--console id="0" display="yes"/-->

    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.11/24</ipv4>
    </if>
    <if id="4" net="ExtNet">
      <ipv4>10.0.10.11/24</ipv4>
    </if>

    <!-- Añadido por Pablo -->
    <if id="3" net="VlanNet">
    </if>

    <!--if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if-->
    <route type="ipv4" gw="10.0.0.1">default</route>

    <!-- Copy ntp config and restart service -->
    <!-- Note: not used because ntp cannot be used inside a container. Clocks are supposed to be synchronized
         between the vms/containers and the host -->
    <!--filetree seq="on_boot" root="/etc/chrony/chrony.conf">conf/ntp/chrony-controller.conf</filetree>
    <exec seq="on_boot" type="verbatim">
        service chrony restart
    </exec-->

    <exec seq="on_boot" type="verbatim">
        # Change MgmtNet and TunnNet interfaces MTU
        ifconfig eth1 mtu 1450
        sed -i -e '/iface eth1 inet static/a \   mtu 1450' /etc/network/interfaces
        #systemd-resolve --set-dns=8.8.8.8 --interface=eth1
	resolvectl dns 2 1.1.1.1

        <!-- Añadido por Pablo. Documentacion: https://access.redhat.com/documentation/es-es/red_hat_enterprise_linux/7/html/networking_guide/sec-configure_802_1q_vlan_tagging_using_the_command_line-->
        ip link add link eth3 name eth3.1005 type vlan id 1005
        ip link set dev eth3.1005 up
        ip addr add 10.10.0.0/24 dev eth3.1005
    </exec>

    <exec seq="setup-nfs" type="verbatim">
        apt install nfs-kernel-server -y
        echo "/kolla_nfs 10.0.0.1/24(rw,sync,no_root_squash)" >> /etc/exports
        chmod 777 /etc/exports
        mkdir /kolla_nfs
        systemctl restart nfs-kernel-server
    </exec>

  </vm>

  <!--
    ~~
    ~~   N E T W O R K   N O D E
    ~~
  -->
  <vm name="network" type="libvirt" subtype="kvm" os="linux" exec_mode="sdisk" arch="x86_64" vcpu="2">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_kvm_ubuntu64-22.04-v025.qcow2</filesystem>
    <mem>4G</mem>
    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.21/24</ipv4>
    </if>
    <if id="2" net="TunnNet">
      <ipv4>10.0.1.21/24</ipv4>
    </if>
    <if id="3" net="VlanNet">
    </if>
    <if id="4" net="ExtNet">
    </if>
    <!--if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if-->
    <route type="ipv4" gw="10.0.0.1">default</route>
    <forwarding type="ip" />
    <forwarding type="ipv6" />

    <exec seq="on_boot" type="verbatim">
        # Change MgmtNet and TunnNet interfaces MTU
        ifconfig eth1 mtu 1450
        sed -i -e '/iface eth1 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth2 mtu 1450
        sed -i -e '/iface eth2 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth3 mtu 1450
        sed -i -e '/iface eth3 inet static/a \   mtu 1450' /etc/network/interfaces
        #systemd-resolve --set-dns=8.8.8.8 --interface=eth1
	resolvectl dns 2 1.1.1.1
        #apt update
	#apt install -y openvswitch-switch
    </exec>

    <!-- Copy ntp config and restart service -->
    <!-- Note: not used because ntp cannot be used inside a container. Clocks are supposed to be synchronized
         between the vms/containers and the host -->
    <!--filetree seq="on_boot" root="/etc/chrony/chrony.conf">conf/ntp/chrony-others.conf</filetree>
    <exec seq="on_boot" type="verbatim">
        service chrony restart
    </exec-->
  </vm>

  <!--
    ~~
    ~~  C O M P U T E 1   N O D E
    ~~
  -->
    <vm name="compute1" type="libvirt" subtype="kvm" os="linux" exec_mode="sdisk" arch="x86_64" vcpu="2">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_kvm_ubuntu64-22.04-v025.qcow2</filesystem>
    <mem>4G</mem>
    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.31/24</ipv4>
    </if>
    <if id="2" net="TunnNet">
      <ipv4>10.0.1.31/24</ipv4>
    </if>
    <if id="3" net="VlanNet">
    </if>
    <if id="4" net="ExtNet">
    </if>
    <!--if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if-->
    <route type="ipv4" gw="10.0.0.1">default</route>

    <exec seq="on_boot" type="verbatim">
        # Create /dev/net/tun device
        #mkdir -p /dev/net/
        #mknod -m 666 /dev/net/tun  c 10 200
        # Change MgmtNet and TunnNet interfaces MTU
        ifconfig eth1 mtu 1450
        sed -i -e '/iface eth1 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth2 mtu 1450
        sed -i -e '/iface eth2 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth3 mtu 1450
        sed -i -e '/iface eth3 inet static/a \   mtu 1450' /etc/network/interfaces
        #systemd-resolve --set-dns=8.8.8.8 --interface=eth1
	resolvectl dns 2 1.1.1.1
        #apt update
	#apt install -y openvswitch-switch

        <!-- Añadido por Pablo. Crear Loopback Devices para Swift -->
        # Crear directorio y archivos de respaldo
        mkdir -p /srv/swift-disk
        cd /srv/swift-disk

        fallocate -l 5G swift-disk1.img
        fallocate -l 5G swift-disk2.img
        fallocate -l 5G swift-disk3.img

        # Asignar dispositivos loopback específicos
        losetup /dev/loop10 /srv/swift-disk/swift-disk1.img
        losetup /dev/loop11 /srv/swift-disk/swift-disk2.img
        losetup /dev/loop12 /srv/swift-disk/swift-disk3.img

        # Formatear y etiquetar los dispositivos loopback
        index=0
        for d in /dev/loop10 /dev/loop11 /dev/loop12; do
            mkfs.xfs -f -L swd${index} ${d}
            (( index++ ))
        done

        # Configurar /etc/fstab y montar los dispositivos
        echo 'LABEL=swd0 /srv/node/swd0 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd1 /srv/node/swd1 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd2 /srv/node/swd2 xfs defaults 0 0' >> /etc/fstab

        mkdir -p /srv/node/swd0
        mkdir -p /srv/node/swd1
        mkdir -p /srv/node/swd2

        mount -a

    </exec>

    <!-- Copy ntp config and restart service -->
    <!-- Note: not used because ntp cannot be used inside a container. Clocks are supposed to be synchronized
         between the vms/containers and the host -->
    <!--filetree seq="on_boot" root="/etc/chrony/chrony.conf">conf/ntp/chrony-others.conf</filetree>
    <exec seq="on_boot" type="verbatim">
        service chrony restart
    </exec-->
  </vm>

  <!--
    ~~~
    ~~~  C O M P U T E 2   N O D E
    ~~~
  -->
  <vm name="compute2" type="libvirt" subtype="kvm" os="linux" exec_mode="sdisk" arch="x86_64" vcpu="2">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_kvm_ubuntu64-22.04-v025.qcow2</filesystem>
    <mem>4G</mem>
    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.32/24</ipv4>
    </if>
    <if id="2" net="TunnNet">
      <ipv4>10.0.1.32/24</ipv4>
    </if>
    <if id="3" net="VlanNet">
    </if>
    <if id="4" net="ExtNet">
    </if>
    <!--if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if-->
    <route type="ipv4" gw="10.0.0.1">default</route>

    <exec seq="on_boot" type="verbatim">
        # Create /dev/net/tun device
        #mkdir -p /dev/net/
        #mknod -m 666 /dev/net/tun  c 10 200
        # Change MgmtNet and TunnNet interfaces MTU
        ifconfig eth1 mtu 1450
        sed -i -e '/iface eth1 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth2 mtu 1450
        sed -i -e '/iface eth2 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth3 mtu 1450
        sed -i -e '/iface eth3 inet static/a \   mtu 1450' /etc/network/interfaces
        #systemd-resolve --set-dns=8.8.8.8 --interface=eth1
	resolvectl dns 2 1.1.1.1
        #apt update
	#apt install -y openvswitch-switch

        <!-- Añadido por Pablo. Crear Loopback Devices para Swift -->
        # Crear directorio y archivos de respaldo
        mkdir -p /srv/swift-disk
        cd /srv/swift-disk

        fallocate -l 5G swift-disk1.img
        fallocate -l 5G swift-disk2.img
        fallocate -l 5G swift-disk3.img

        # Asignar dispositivos loopback específicos
        losetup /dev/loop10 /srv/swift-disk/swift-disk1.img
        losetup /dev/loop11 /srv/swift-disk/swift-disk2.img
        losetup /dev/loop12 /srv/swift-disk/swift-disk3.img

        # Formatear y etiquetar los dispositivos loopback
        index=0
        for d in /dev/loop10 /dev/loop11 /dev/loop12; do
            mkfs.xfs -f -L swd${index} ${d}
            (( index++ ))
        done

        # Configurar /etc/fstab y montar los dispositivos
        echo 'LABEL=swd0 /srv/node/swd0 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd1 /srv/node/swd1 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd2 /srv/node/swd2 xfs defaults 0 0' >> /etc/fstab

        mkdir -p /srv/node/swd0
        mkdir -p /srv/node/swd1
        mkdir -p /srv/node/swd2

        mount -a

    </exec>

    <!-- Copy ntp config and restart service -->
    <!-- Note: not used because ntp cannot be used inside a container. Clocks are supposed to be synchronized
         between the vms/containers and the host -->
    <!--filetree seq="on_boot" root="/etc/chrony/chrony.conf">conf/ntp/chrony-others.conf</filetree>
    <exec seq="on_boot" type="verbatim">
        service chrony restart
    </exec-->
  </vm>

  <!--
    ~~~
    ~~~  C O M P U T E 3   N O D E
    ~~~
  -->
  <vm name="compute3" type="libvirt" subtype="kvm" os="linux" exec_mode="sdisk" arch="x86_64" vcpu="2">
    <filesystem type="cow">/usr/share/vnx/filesystems/vnx_rootfs_kvm_ubuntu64-22.04-v025.qcow2</filesystem>
    <mem>4G</mem>
    <if id="1" net="MgmtNet">
      <ipv4>10.0.0.33/24</ipv4>
    </if>
    <if id="2" net="TunnNet">
      <ipv4>10.0.1.33/24</ipv4>
    </if>
    <if id="3" net="VlanNet">
    </if>
    <if id="4" net="ExtNet">
    </if>
    <!--if id="9" net="virbr0">
      <ipv4>dhcp</ipv4>
    </if-->
    <route type="ipv4" gw="10.0.0.1">default</route>

    <exec seq="on_boot" type="verbatim">
        # Create /dev/net/tun device
        #mkdir -p /dev/net/
        #mknod -m 666 /dev/net/tun  c 10 200
        # Change MgmtNet and TunnNet interfaces MTU
        ifconfig eth1 mtu 1450
        sed -i -e '/iface eth1 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth2 mtu 1450
        sed -i -e '/iface eth2 inet static/a \   mtu 1450' /etc/network/interfaces
        ifconfig eth3 mtu 1450
        sed -i -e '/iface eth3 inet static/a \   mtu 1450' /etc/network/interfaces
        #systemd-resolve --set-dns=8.8.8.8 --interface=eth1
	resolvectl dns 2 1.1.1.1
        #apt update
	#apt install -y openvswitch-switch

        <!-- Añadido por Pablo. Crear Loopback Devices para Swift -->
        # Crear directorio y archivos de respaldo
        mkdir -p /srv/swift-disk
        cd /srv/swift-disk

        fallocate -l 5G swift-disk1.img
        fallocate -l 5G swift-disk2.img
        fallocate -l 5G swift-disk3.img

        # Asignar dispositivos loopback específicos
        losetup /dev/loop10 /srv/swift-disk/swift-disk1.img
        losetup /dev/loop11 /srv/swift-disk/swift-disk2.img
        losetup /dev/loop12 /srv/swift-disk/swift-disk3.img

        # Formatear y etiquetar los dispositivos loopback
        index=0
        for d in /dev/loop10 /dev/loop11 /dev/loop12; do
            mkfs.xfs -f -L swd${index} ${d}
            (( index++ ))
        done

        # Configurar /etc/fstab y montar los dispositivos
        echo 'LABEL=swd0 /srv/node/swd0 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd1 /srv/node/swd1 xfs defaults 0 0' >> /etc/fstab
        echo 'LABEL=swd2 /srv/node/swd2 xfs defaults 0 0' >> /etc/fstab

        mkdir -p /srv/node/swd0
        mkdir -p /srv/node/swd1
        mkdir -p /srv/node/swd2

        mount -a

    </exec>

    <!-- Copy ntp config and restart service -->
    <!-- Note: not used because ntp cannot be used inside a container. Clocks are supposed to be synchronized
         between the vms/containers and the host -->
    <!--filetree seq="on_boot" root="/etc/chrony/chrony.conf">conf/ntp/chrony-others.conf</filetree>
    <exec seq="on_boot" type="verbatim">
        service chrony restart
    </exec-->
  </vm>

  <!--
    ~~
    ~~   H O S T   N O D E
    ~~
  -->
  <host>
    <hostif net="ExtNet">
       <ipv4>10.0.10.1/24</ipv4>
    </hostif>
    <hostif net="MgmtNet">
      <ipv4>10.0.0.2/24</ipv4>
    </hostif>

  </host>


</vnx>